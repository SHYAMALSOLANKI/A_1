import json
import os
import logging
from datasets import load_dataset

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

OUTPUT_FILE = "training_data/curriculum.jsonl"
os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)

def download_and_process():
    logger.info("Starting High-Quality Curriculum Download...")
    curriculum_data = []

    # 1. GSM8K (Grade School Math 8K)
    # Source: OpenAI. High quality multi-step reasoning.
    # We only take the QUESTION. The 'answer' is generated by our model + audited by Stack Server.
    try:
        logger.info("Downloading GSM8K (main)...")
        dataset = load_dataset("gsm8k", "main", split="train")
        
        # Take top 500 for initial curriculum to verify loop works
        # We can scale this up later.
        for item in dataset.select(range(500)): 
            prompt = f"User: {item['question']}\nDRAFT:"
            curriculum_data.append({"text": prompt, "source": "gsm8k", "type": "math"})
            
        logger.info(f"Added {len(curriculum_data)} math reasoning prompts.")
    except Exception as e:
        logger.error(f"Failed to load GSM8K: {e}")

    # 2. Logic / Reasoning (Simple Logic)
    # Using a small synthetic set for basic logical consistency checks
    
    logic_prompts = [
        "User: If all cats are mammals, and some mammals are dogs, are some cats dogs?\nDRAFT:",
        "User: Explain why a square is a rectangle but a rectangle is not necessarily a square.\nDRAFT:",
        "User: Analyze the logical fallacy in: 'It rained because I washed my car.'\nDRAFT:",
        "User: If P implies Q, and Q is false, what can we conclude about P?\nDRAFT:",
        "User: Construct a syllogism that is valid but unsound.\nDRAFT:"
    ]
    
    for p in logic_prompts:
        curriculum_data.append({"text": p, "source": "manual_logic", "type": "logic"})

    # 3. SlimOrca (Chain-of-Thought Reasoning) - High Volume for Chinchilla Scaling
    # We need ~1M tokens to start meaningful training. 
    # SlimOrca / OpenOrca contains robust "User: ... \n System: ..." pairs.
    # We will extract 50,000 Questions to get ~25M-50M potential tokens per epoch.
    try:
        logger.info("Downloading SlimOrca (subset)...")
        # Streaming to avoid massive download
        dataset_orca = load_dataset("Open-Orca/SlimOrca", split="train", streaming=True)
        
        count = 0
        target_count = 50000 
        
        for item in dataset_orca:
            if count >= target_count:
                break
                
            # SlimOrca format: {'conversations': [{'from': 'human', 'value': '...'}, {'from': 'gpt', 'value': '...'}]}
            convs = item.get("conversations", [])
            if convs and convs[0]['from'] == 'human':
                question = convs[0]['value']
                # Filter out very short or very long prompts
                if 20 < len(question) < 1000:
                    prompt = f"User: {question}\nDRAFT:"
                    curriculum_data.append({"text": prompt, "source": "slim_orca", "type": "reasoning"})
                    count += 1
                    
        logger.info(f"Added {count} reasoning prompts from SlimOrca.")
    except Exception as e:
        logger.error(f"Failed to load SlimOrca: {e}")

    # Write to file
    logger.info(f"Writing {len(curriculum_data)} prompts to {OUTPUT_FILE}...")
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        for entry in curriculum_data:
            f.write(json.dumps(entry) + "\n")
            
    logger.info("Curriculum preparation complete.")

if __name__ == "__main__":
    download_and_process()
