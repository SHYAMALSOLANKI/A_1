import json
import re
import random
import os
import sys

# Ensure we can import from services
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from services.stacks.pps import PPS
from services.stacks.cae import CAE
from services.stacks.irq import IRQ

# Configuration
INPUT_FILE = r'c:\Users\Shyamal solanki\A_1\training_data\corpus_raw.jsonl'
OUTPUT_FILE = r'c:\Users\Shyamal solanki\A_1\training_data\drrl_training_data.jsonl'
MAX_SAMPLES = 50000 

def clean_latex(text):
    """
    Strips LaTeX to get 'Ground Truth' / 'Ideal Revision'
    """
    text = re.sub(r'\\documentclass\[.*?\]\{.*?\}', '', text)
    text = re.sub(r'\\usepackage\[.*?\]\{.*?\}', '', text)
    text = re.sub(r'\\begin\{.*?\}', '', text)
    text = re.sub(r'\\end\{.*?\}', '', text)
    text = re.sub(r'\\[a-zA-Z]+\{', '', text) 
    text = re.sub(r'\}', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def create_bad_draft(text):
    """
    Intentionally creates a draft that fails the CAE checks
    to force the model to learn from the IRQ.
    """
    failure_mode = random.choice(['latex_leak', 'too_short', 'repetitive'])
    
    if failure_mode == 'latex_leak':
        # Inject some fake latex
        return text[:100] + " \\begin{equation} " + text[100:200]
    elif failure_mode == 'too_short':
        return text[:15]
    elif failure_mode == 'repetitive':
        chunk = text[:50]
        return (chunk + " ") * 5
    
    return text # Fallback

def main():
    print("Initializing DRRL Stacks...")
    pps = PPS()
    cae = CAE(pps)
    irq = IRQ(pps)
    
    print(f"Processing {INPUT_FILE}...")
    if not os.path.exists(INPUT_FILE):
        print(f"Error: {INPUT_FILE} not found. Did you rename it?")
        return

    count = 0
    with open(INPUT_FILE, 'r', encoding='utf-8') as fin, \
         open(OUTPUT_FILE, 'w', encoding='utf-8') as fout:
        
        for line in fin:
            if count >= MAX_SAMPLES:
                break
            
            try:
                # 1. Get the Raw Content
                try: 
                    entry = json.loads(line)
                    raw_content = entry.get('text', '')
                except:
                    raw_content = line # Handle plain lines
                
                # 2. Establish Ground Truth (The Revision)
                ground_truth = clean_latex(raw_content)
                if len(ground_truth) < 50: 
                    continue
                    
                # 3. Simulate the 'Draft' Phase (The Model trying and failing)
                # We intentionally break the draft so the CAE has something to Audit
                draft_text = create_bad_draft(ground_truth)
                
                # 4. Run the Stacks (Backend Logic)
                audit_result = cae.audit_draft(draft_text)
                
                # If by chance it passed (random), skip validation training for this sample
                if audit_result['status'] == 'PASS':
                    continue
                    
                # 5. Generate the Intervention
                intervention = irq.generate_intervention(audit_result)
                
                # 6. Simulate the 'Reflect' Phase (The Model acknowledging the feedback)
                # Ideally, this would be generated by a Teacher Model. 
                # For now, we use a template based on the violation.
                violation = audit_result['violations'][0]
                reflection = f"REFLECT: The backend has flagged a {violation}. "
                if violation == "LATEX_LEAKAGE":
                    reflection += "I included raw LaTeX commands which violates the syntax policy. I must strip them."
                elif violation == "DRAFT_TOO_SHORT":
                    reflection += "The response was too brief and lacked definition. I need to expand."
                
                # 7. Construct the Full Training Context
                # User Prompt -> Draft -> Backend -> Reflect -> Revision
                user_prompt = f"User: Explain the following content: {ground_truth[:30]}..."
                
                full_sequence = (
                    f"{user_prompt}\n"
                    f"DRAFT: {draft_text}\n"
                    f"{intervention}\n" # The Injection
                    f"{reflection}\n"
                    f"REVISE: {ground_truth}\n"
                    f"LEARNED: Always check for {violation} before finalizing."
                )
                
                new_entry = {
                    "text": full_sequence,
                    "source": "drrl_synthetic_v1",
                    "type": "audit_trace"
                }

                fout.write(json.dumps(new_entry) + '\n')
                count += 1
                
                if count % 1000 == 0:
                    print(f"Generated {count} training traces...")
                    
            except Exception as e:
                # print(f"Skipping line due to error: {e}")
                continue

    print(f"Success. Generated {count} robust training traces at {OUTPUT_FILE}")

if __name__ == "__main__":
    main()
